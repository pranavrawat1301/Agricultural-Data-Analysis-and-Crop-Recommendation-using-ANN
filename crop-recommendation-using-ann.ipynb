{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6787965,"sourceType":"datasetVersion","datasetId":3905501}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Crop Recommendation System Using ANNs ","metadata":{}},{"cell_type":"markdown","source":"**Importing the libraries**\n\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:29.009474Z","iopub.execute_input":"2023-10-29T21:25:29.009863Z","iopub.status.idle":"2023-10-29T21:25:36.311517Z","shell.execute_reply.started":"2023-10-29T21:25:29.009829Z","shell.execute_reply":"2023-10-29T21:25:36.310597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Importing the dataset**\n\nA Data set from Kaggle is used for training the ANN","metadata":{}},{"cell_type":"code","source":"dataset = pd.read_csv('/kaggle/input/crop-recommendation-dataset/Crop_recommendation.csv')\nX=dataset.drop(labels=['label'], axis=1)\ny = dataset.iloc[:, -1].values","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:36.313050Z","iopub.execute_input":"2023-10-29T21:25:36.313579Z","iopub.status.idle":"2023-10-29T21:25:36.351072Z","shell.execute_reply.started":"2023-10-29T21:25:36.313552Z","shell.execute_reply":"2023-10-29T21:25:36.350054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Splitting the dataset into the Training set and Test set**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, train_size=0.80, random_state = 1)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:36.352270Z","iopub.execute_input":"2023-10-29T21:25:36.352567Z","iopub.status.idle":"2023-10-29T21:25:36.760144Z","shell.execute_reply.started":"2023-10-29T21:25:36.352542Z","shell.execute_reply":"2023-10-29T21:25:36.759041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**EDA and visualizing the features :**\n\nPlotting the Humidity and Rainfall for various crops.","metadata":{}},{"cell_type":"code","source":"unique_features = np.unique(dataset['label'])\nprint(unique_features)\n\nplt.figure(figsize=(22.5,13.5))\nfor feature in unique_features:\n    data_subset = dataset[dataset['label'] == feature]\n    plt.scatter(data_subset['humidity'], data_subset['rainfall'], label=feature, marker='o')\n    \nplt.xlabel('Humidity (%)')\nplt.ylabel('Rainfall (mm)')\nplt.title('Scatterplot of Humidity vs Rainfall')\nplt.legend(loc='upper left')\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:36.762717Z","iopub.execute_input":"2023-10-29T21:25:36.763080Z","iopub.status.idle":"2023-10-29T21:25:37.769091Z","shell.execute_reply.started":"2023-10-29T21:25:36.763051Z","shell.execute_reply":"2023-10-29T21:25:37.768225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now plotting them one crop at a time for suitable temperature at which different crops can grow.**","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nfor feature in unique_features:\n    data_subset = dataset[dataset['label'] == feature]\n    sns.distplot(data_subset['temperature'])\n    plt.title(feature)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:37.770268Z","iopub.execute_input":"2023-10-29T21:25:37.770730Z","iopub.status.idle":"2023-10-29T21:25:44.184268Z","shell.execute_reply.started":"2023-10-29T21:25:37.770694Z","shell.execute_reply":"2023-10-29T21:25:44.182818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now , Plotting a Bar graph with mean temperature at which every crop grows**.","metadata":{}},{"cell_type":"code","source":"for feature in unique_features:\n    data_subset = dataset[dataset['label'] == feature]\n    mean_of_temps = np.mean(data_subset['temperature'])\n    plt.barh(feature , mean_of_temps)\n    plt.grid(True)\n    \n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:44.186026Z","iopub.execute_input":"2023-10-29T21:25:44.186354Z","iopub.status.idle":"2023-10-29T21:25:44.536747Z","shell.execute_reply.started":"2023-10-29T21:25:44.186327Z","shell.execute_reply":"2023-10-29T21:25:44.535707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Feature Engineering**","metadata":{}},{"cell_type":"markdown","source":"**Dropping constant Features** \n\nFeatures with a very minute or no change throghout the dataset are redundant and hence can be removed from the dataset because these sort of features are redundant and add nothing to the model during it's learning.\nHere we are setting our Variance(Measurment of how spread out or dispersed the values are, indicating data's variability) Threshold as 0.5.\nMeaning any column with variance less than 0.5 will be removed.","metadata":{}},{"cell_type":"code","source":"X_train = pd.DataFrame(X_train)\nfrom sklearn.feature_selection import VarianceThreshold\nvar_thres=VarianceThreshold(threshold=0)\nvar_thres.fit(X_train)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:44.538293Z","iopub.execute_input":"2023-10-29T21:25:44.538952Z","iopub.status.idle":"2023-10-29T21:25:44.758829Z","shell.execute_reply.started":"2023-10-29T21:25:44.538914Z","shell.execute_reply":"2023-10-29T21:25:44.757745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"var_thres.get_support()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:44.760073Z","iopub.execute_input":"2023-10-29T21:25:44.760387Z","iopub.status.idle":"2023-10-29T21:25:44.766792Z","shell.execute_reply.started":"2023-10-29T21:25:44.760359Z","shell.execute_reply":"2023-10-29T21:25:44.765820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"=>No column in the dataset has been found wiht a variance of or below 0.5","metadata":{}},{"cell_type":"markdown","source":"\n\n**Getting the columns with variance more than 0.5 i.e.,ALL**","metadata":{}},{"cell_type":"code","source":"X_train.columns[var_thres.get_support()]","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:44.767870Z","iopub.execute_input":"2023-10-29T21:25:44.768136Z","iopub.status.idle":"2023-10-29T21:25:44.778473Z","shell.execute_reply.started":"2023-10-29T21:25:44.768114Z","shell.execute_reply":"2023-10-29T21:25:44.777504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***A piece of code that can be used to remove the columns with constant or almost constant entries without dropping the columns manually can be.***","metadata":{}},{"cell_type":"code","source":"constant_columns = [column for column in X_train.columns\n                    if column not in X_train.columns[var_thres.get_support()]]\nprint(constant_columns)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:44.782110Z","iopub.execute_input":"2023-10-29T21:25:44.782827Z","iopub.status.idle":"2023-10-29T21:25:44.789675Z","shell.execute_reply.started":"2023-10-29T21:25:44.782798Z","shell.execute_reply":"2023-10-29T21:25:44.788835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we have no column with such condition the variable constant column is an empty list.\n\nAnd hence in the code below no column will be dropped.","metadata":{}},{"cell_type":"code","source":"X_train.drop(constant_columns,axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:44.790891Z","iopub.execute_input":"2023-10-29T21:25:44.791222Z","iopub.status.idle":"2023-10-29T21:25:44.814850Z","shell.execute_reply.started":"2023-10-29T21:25:44.791198Z","shell.execute_reply":"2023-10-29T21:25:44.814124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Removing the highly co-related Features (Using Pearson Correlation)** \n\nRemoving highly correlated features is important in feature selection because it helps reduce redundancy and multicollinearity, which can lead to unstable model estimates and make it challenging for machine learning algorithms to learn the true relationships between variables.","metadata":{}},{"cell_type":"code","source":"cor = X_train.corr()\nprint(cor)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:44.816035Z","iopub.execute_input":"2023-10-29T21:25:44.816327Z","iopub.status.idle":"2023-10-29T21:25:44.827232Z","shell.execute_reply.started":"2023-10-29T21:25:44.816302Z","shell.execute_reply":"2023-10-29T21:25:44.826454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now this is the correlation between various features now a heatmap will be used to demonstrate these values better.**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,10))\ncor = X_train.corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.CMRmap_r)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:44.828377Z","iopub.execute_input":"2023-10-29T21:25:44.829220Z","iopub.status.idle":"2023-10-29T21:25:45.260715Z","shell.execute_reply.started":"2023-10-29T21:25:44.829191Z","shell.execute_reply":"2023-10-29T21:25:45.259713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**As we can see in the above heatmap that the Phosphorus(P) and Pottasium(K) content in the soil are highly correlated (0.73)**","metadata":{}},{"cell_type":"markdown","source":"**Therefore a function is defined which removes the Features(one of them) with correlation above a certain threshold (in this case set to be as 0.7).**","metadata":{}},{"cell_type":"code","source":"def correlation(dataset, threshold):\n    col_corr = set()  \n    corr_matrix = dataset.corr()\n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute value and not is it is negatively correlated or positively\n                colname = corr_matrix.columns[i] \n                col_corr.add(colname)\n    return col_corr","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:45.262210Z","iopub.execute_input":"2023-10-29T21:25:45.262662Z","iopub.status.idle":"2023-10-29T21:25:45.271898Z","shell.execute_reply.started":"2023-10-29T21:25:45.262628Z","shell.execute_reply":"2023-10-29T21:25:45.270945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_features = correlation(X_train, 0.7)\nlen(set(corr_features))","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:45.273255Z","iopub.execute_input":"2023-10-29T21:25:45.273534Z","iopub.status.idle":"2023-10-29T21:25:45.289083Z","shell.execute_reply.started":"2023-10-29T21:25:45.273510Z","shell.execute_reply":"2023-10-29T21:25:45.288192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The list of correlated features are :** ","metadata":{}},{"cell_type":"code","source":"corr_features","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:45.290344Z","iopub.execute_input":"2023-10-29T21:25:45.290679Z","iopub.status.idle":"2023-10-29T21:25:45.297404Z","shell.execute_reply.started":"2023-10-29T21:25:45.290652Z","shell.execute_reply":"2023-10-29T21:25:45.296750Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So , The above feature(\"Pottasium\") will be dropped from trainig tst and test set. ","metadata":{}},{"cell_type":"code","source":"X_train.drop(corr_features,axis=1)\nX_test.drop(corr_features,axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:45.298399Z","iopub.execute_input":"2023-10-29T21:25:45.298842Z","iopub.status.idle":"2023-10-29T21:25:45.317562Z","shell.execute_reply.started":"2023-10-29T21:25:45.298816Z","shell.execute_reply":"2023-10-29T21:25:45.316491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now , The features and their relation with the dependant variable will be found basically the importance of the various features.**","metadata":{}},{"cell_type":"markdown","source":"The feature importance of each feature of the dataset is determined using the feature importance property of the model.\n\nFeature importance gives a score for each feature of the data, the higher the score more important or relevant is the feature towards the output variable.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\nimport matplotlib.pyplot as plt\nmodel = ExtraTreesClassifier()\nmodel.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:45.318950Z","iopub.execute_input":"2023-10-29T21:25:45.319463Z","iopub.status.idle":"2023-10-29T21:25:45.705812Z","shell.execute_reply.started":"2023-10-29T21:25:45.319427Z","shell.execute_reply":"2023-10-29T21:25:45.704827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model.feature_importances_)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:45.707070Z","iopub.execute_input":"2023-10-29T21:25:45.707376Z","iopub.status.idle":"2023-10-29T21:25:45.718974Z","shell.execute_reply.started":"2023-10-29T21:25:45.707348Z","shell.execute_reply":"2023-10-29T21:25:45.717893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**A bar graph showing the features and their importance :**","metadata":{}},{"cell_type":"code","source":"ranked_features=pd.Series(model.feature_importances_,index=X.columns)\nranked_features.plot(kind='barh')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:45.720107Z","iopub.execute_input":"2023-10-29T21:25:45.720426Z","iopub.status.idle":"2023-10-29T21:25:45.962795Z","shell.execute_reply.started":"2023-10-29T21:25:45.720400Z","shell.execute_reply":"2023-10-29T21:25:45.961820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So , as we can the see the most important feature is the rainfall and the least important is pH and therre is no feature with drastically less importance then than the others.\n\n**Therefore, NO FEATURE will be removed in this step.**","metadata":{}},{"cell_type":"markdown","source":"**Finding Outliers** \n\nWe need to remove the outliers as the ANNs are highly sensitive to outliers in the data.","metadata":{}},{"cell_type":"markdown","source":"There are two methods to find outliers in a data set :\n\n1)Using Z-Score (If the data is normally distributed)\n\n2)Using IQR (If the distribution is skewed)","metadata":{}},{"cell_type":"markdown","source":"**Plotting the \"Distplot\" for various features (training set values)**","metadata":{}},{"cell_type":"code","source":"for column in X.columns:\n    sns.distplot(X_train[column])\n    plt.show() #For showing different features in different graphs ","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:45.963877Z","iopub.execute_input":"2023-10-29T21:25:45.964155Z","iopub.status.idle":"2023-10-29T21:25:48.169181Z","shell.execute_reply.started":"2023-10-29T21:25:45.964130Z","shell.execute_reply":"2023-10-29T21:25:48.168427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Therefore , pH and Temprature are the only normal distributions amongst all the features so Z-Score will be applied on them.**","metadata":{}},{"cell_type":"markdown","source":"First we need to combine X_train and Y_train to get a collective training set and then convert the resulting array into a pandas dataframe so as to get the column names.","metadata":{}},{"cell_type":"code","source":"training_set = np.column_stack((X_train, y_train))\nprint(training_set)\ntraining_set_labeled = pd.DataFrame(training_set, columns=dataset.columns)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:48.170301Z","iopub.execute_input":"2023-10-29T21:25:48.171235Z","iopub.status.idle":"2023-10-29T21:25:48.177725Z","shell.execute_reply.started":"2023-10-29T21:25:48.171205Z","shell.execute_reply":"2023-10-29T21:25:48.176791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def detect_outliers(data):\n    outliers = []\n    threshold=3.5\n    mean = np.mean(data)\n    std =np.std(data)\n    \n    \n    for i in data:\n        z_score= (i - mean)/std \n        if np.abs(z_score) > threshold:\n            outliers.append(i)\n    return outliers","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:48.178751Z","iopub.execute_input":"2023-10-29T21:25:48.179534Z","iopub.status.idle":"2023-10-29T21:25:48.187112Z","shell.execute_reply.started":"2023-10-29T21:25:48.179506Z","shell.execute_reply":"2023-10-29T21:25:48.186250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outlier_ph=detect_outliers(X_train.ph)\noutlier_ph","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:48.188491Z","iopub.execute_input":"2023-10-29T21:25:48.188809Z","iopub.status.idle":"2023-10-29T21:25:48.202526Z","shell.execute_reply.started":"2023-10-29T21:25:48.188760Z","shell.execute_reply":"2023-10-29T21:25:48.201670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**So,The above values are the outliers and hence need ot be removed from the dataset.**","metadata":{}},{"cell_type":"code","source":"training_set_labeled = training_set_labeled[~training_set_labeled['ph'].isin(outlier_ph)]\ntraining_set_labeled.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:48.203836Z","iopub.execute_input":"2023-10-29T21:25:48.204164Z","iopub.status.idle":"2023-10-29T21:25:48.214000Z","shell.execute_reply.started":"2023-10-29T21:25:48.204137Z","shell.execute_reply":"2023-10-29T21:25:48.212916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The same will be done for temperature.","metadata":{}},{"cell_type":"code","source":"outlier_temp=detect_outliers(X_train.temperature)\noutlier_temp","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:48.215081Z","iopub.execute_input":"2023-10-29T21:25:48.215694Z","iopub.status.idle":"2023-10-29T21:25:48.225919Z","shell.execute_reply.started":"2023-10-29T21:25:48.215665Z","shell.execute_reply":"2023-10-29T21:25:48.224797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_set_labeled = training_set_labeled[~training_set_labeled['temperature'].isin(outlier_temp)]\ntraining_set_labeled.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:48.227201Z","iopub.execute_input":"2023-10-29T21:25:48.227691Z","iopub.status.idle":"2023-10-29T21:25:48.236921Z","shell.execute_reply.started":"2023-10-29T21:25:48.227655Z","shell.execute_reply":"2023-10-29T21:25:48.235882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So,The outliers from these two features are removed from the dataset","metadata":{}},{"cell_type":"markdown","source":"Now , The outliers from the more skewed distributions (N,P,K,Humidity and Rainfall)\n\n**They'll be removed by using the Inter-Quantile Range (IQR).**","metadata":{}},{"cell_type":"code","source":"def detect_outliers_quantile(data):\n    outliers = []\n    threshold=3\n    quantile1, quantile3= np.percentile(data,[25,75])\n    iqr=quantile3-quantile1\n    \n    upper_bridge=quantile3 +(threshold * iqr)\n    lower_bridge=quantile1 -(threshold * iqr)\n    \n    \n    for i in data:\n        if i > upper_bridge or i < lower_bridge:\n            outliers.append(i)\n    return outliers","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:48.243151Z","iopub.execute_input":"2023-10-29T21:25:48.243700Z","iopub.status.idle":"2023-10-29T21:25:48.248613Z","shell.execute_reply.started":"2023-10-29T21:25:48.243671Z","shell.execute_reply":"2023-10-29T21:25:48.247953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**So , The outliers are needed to be found out and then removed.** \n\n\n(Generally, it should be removed but removing them here is leading to a loss of two classes in y_train so it will not be removed here.)","metadata":{}},{"cell_type":"code","source":"unique_values = np.unique(training_set_labeled['label'])\nprint(unique_values.shape )\nskewed_features = [X_train.N , X_train.P , X_train.K , X_train.humidity , X_train.rainfall]\n\nfor i in skewed_features:\n    outlier_skewed = detect_outliers_quantile(i)\n    print('Outliers in ' , i.name)\n    print(outlier_skewed)\n    #training_set_labeled = training_set_labeled[~training_set_labeled[i.name].isin(outlier_skewed)]\n    print(training_set_labeled.shape)\n    unique_values = np.unique(training_set_labeled['label'])\n    print(unique_values.shape )\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:48.249975Z","iopub.execute_input":"2023-10-29T21:25:48.251568Z","iopub.status.idle":"2023-10-29T21:25:48.274380Z","shell.execute_reply.started":"2023-10-29T21:25:48.251539Z","shell.execute_reply":"2023-10-29T21:25:48.273413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_set_labeled.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:48.275666Z","iopub.execute_input":"2023-10-29T21:25:48.275976Z","iopub.status.idle":"2023-10-29T21:25:48.281691Z","shell.execute_reply.started":"2023-10-29T21:25:48.275950Z","shell.execute_reply":"2023-10-29T21:25:48.280703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Creating X_train and y_train again.","metadata":{}},{"cell_type":"code","source":"X_train = training_set_labeled.iloc[ : , :-1].values \ny_train = training_set_labeled.iloc[ : , 7:8].values #to get a 2-D array \nprint(X_train.shape)\nprint(y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:48.283157Z","iopub.execute_input":"2023-10-29T21:25:48.283487Z","iopub.status.idle":"2023-10-29T21:25:48.293916Z","shell.execute_reply.started":"2023-10-29T21:25:48.283461Z","shell.execute_reply":"2023-10-29T21:25:48.292923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test = y_test.reshape(-1, 1)\nprint(y_test.shape)\ny_new = np.row_stack((y_train, y_test))\nprint(y_new.shape)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:48.295135Z","iopub.execute_input":"2023-10-29T21:25:48.295752Z","iopub.status.idle":"2023-10-29T21:25:48.303222Z","shell.execute_reply.started":"2023-10-29T21:25:48.295722Z","shell.execute_reply":"2023-10-29T21:25:48.302350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Feature Extraction :**\n\nWe will be using the **Linear Discriminant analysis (LDA)** for feature extraction technique.\n\nLDA is used to generate seperation between classes by making new features using the existing set of features without much loss in variance of the data.","metadata":{}},{"cell_type":"markdown","source":"**For LDA first we have to perform feature scaling**","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:48.304405Z","iopub.execute_input":"2023-10-29T21:25:48.304704Z","iopub.status.idle":"2023-10-29T21:25:48.318320Z","shell.execute_reply.started":"2023-10-29T21:25:48.304678Z","shell.execute_reply":"2023-10-29T21:25:48.317545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Applying LDA**","metadata":{}},{"cell_type":"code","source":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nlda = LDA(n_components = 5)\nX_train = lda.fit_transform(X_train, y_train)\nX_test = lda.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:48.319437Z","iopub.execute_input":"2023-10-29T21:25:48.319964Z","iopub.status.idle":"2023-10-29T21:25:48.369899Z","shell.execute_reply.started":"2023-10-29T21:25:48.319936Z","shell.execute_reply":"2023-10-29T21:25:48.368834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**One hot-encoding the dependent variable**\n\nOne-hot encoding is an important preprocessing step when training an Artificial Neural Network (ANN) because it allows the network to effectively handle categorical data, which is in a non-numeric format.","metadata":{}},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(sparse=False), [0])], remainder='passthrough',)\ny_train= np.array(ct.fit_transform(y_train)) \nprint(y_train)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:48.371586Z","iopub.execute_input":"2023-10-29T21:25:48.372291Z","iopub.status.idle":"2023-10-29T21:25:48.414819Z","shell.execute_reply.started":"2023-10-29T21:25:48.372252Z","shell.execute_reply":"2023-10-29T21:25:48.413812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***sparse=False***\n\nIs Important so as to convert the Sparse matrix which the Encoder will return to a dense matrix which will then be conviniently used by the ANN","metadata":{}},{"cell_type":"markdown","source":"**Building the ANN**","metadata":{}},{"cell_type":"markdown","source":"**Initializing the ANN**","metadata":{}},{"cell_type":"code","source":"ann = tf.keras.models.Sequential()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:48.416201Z","iopub.execute_input":"2023-10-29T21:25:48.417131Z","iopub.status.idle":"2023-10-29T21:25:48.498919Z","shell.execute_reply.started":"2023-10-29T21:25:48.417087Z","shell.execute_reply":"2023-10-29T21:25:48.497845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Adding layers to the ANN**","metadata":{}},{"cell_type":"code","source":"ann.add(tf.keras.layers.Dense(units=10, activation='relu'))\nann.add(tf.keras.layers.Dense(units=20, activation='relu'))\nann.add(tf.keras.layers.Dense(units=22, activation='softmax')) #Output layer ","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:48.500228Z","iopub.execute_input":"2023-10-29T21:25:48.500541Z","iopub.status.idle":"2023-10-29T21:25:48.514634Z","shell.execute_reply.started":"2023-10-29T21:25:48.500514Z","shell.execute_reply":"2023-10-29T21:25:48.513837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Compiling the ANN**","metadata":{}},{"cell_type":"code","source":"ann.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:48.515652Z","iopub.execute_input":"2023-10-29T21:25:48.515960Z","iopub.status.idle":"2023-10-29T21:25:48.550733Z","shell.execute_reply.started":"2023-10-29T21:25:48.515934Z","shell.execute_reply":"2023-10-29T21:25:48.549984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Training the ANN on the Training set**","metadata":{}},{"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:48.551687Z","iopub.execute_input":"2023-10-29T21:25:48.552451Z","iopub.status.idle":"2023-10-29T21:25:48.557928Z","shell.execute_reply.started":"2023-10-29T21:25:48.552423Z","shell.execute_reply":"2023-10-29T21:25:48.556680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ann.fit(X_train, y_train, batch_size = 128, epochs = 200)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:48.559416Z","iopub.execute_input":"2023-10-29T21:25:48.559691Z","iopub.status.idle":"2023-10-29T21:25:54.879730Z","shell.execute_reply.started":"2023-10-29T21:25:48.559667Z","shell.execute_reply":"2023-10-29T21:25:54.878547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Predicting a result** ","metadata":{}},{"cell_type":"code","source":"pred = ann.predict(lda.transform(sc.transform([[91,43,44,21.87974,83.00027,6.5111,203.9355]])))\npred = ct.named_transformers_['encoder'].inverse_transform(pred)\nprint(pred)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T21:25:54.880934Z","iopub.execute_input":"2023-10-29T21:25:54.881246Z","iopub.status.idle":"2023-10-29T21:25:55.026859Z","shell.execute_reply.started":"2023-10-29T21:25:54.881219Z","shell.execute_reply":"2023-10-29T21:25:55.025823Z"},"trusted":true},"execution_count":null,"outputs":[]}]}